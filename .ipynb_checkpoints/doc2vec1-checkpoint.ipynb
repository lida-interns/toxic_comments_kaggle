{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import os\n",
    "\n",
    "#train_data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "def read_corpus(input_data, tokens_only=False):\n",
    "    for i, comment in enumerate(input_data):\n",
    "        if tokens_only:\n",
    "            yield gensim.utils.simple_preprocess(comment)\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(comment), [i])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(train_data.comment_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['nonsense', 'kiss', 'off', 'geek', 'what', 'said', 'is', 'true', 'll', 'have', 'your', 'account', 'terminated'], tags=[0]), TaggedDocument(words=['please', 'do', 'not', 'vandalize', 'pages', 'as', 'you', 'did', 'with', 'this', 'edit', 'to', 'merwin', 'if', 'you', 'continue', 'to', 'do', 'so', 'you', 'will', 'be', 'blocked', 'from', 'editing'], tags=[1]), TaggedDocument(words=['points', 'of', 'interest', 'removed', 'the', 'points', 'of', 'interest', 'section', 'you', 'added', 'because', 'it', 'seemed', 'kind', 'of', 'spammy', 'know', 'you', 'probably', 'didn', 'mean', 'to', 'disobey', 'the', 'rules', 'but', 'generally', 'point', 'of', 'interest', 'tends', 'to', 'be', 'rather', 'touristy', 'and', 'quite', 'irrelevant', 'to', 'an', 'area', 'culture', 'that', 'just', 'my', 'opinion', 'though', 'if', 'you', 'want', 'to', 'reply', 'just', 'put', 'your', 'reply', 'here', 'and', 'add', 'talkback', 'jamiegraham', 'on', 'my', 'talkpage'], tags=[2]), TaggedDocument(words=['asking', 'some', 'his', 'nationality', 'is', 'racial', 'offence', 'wow', 'wasn', 'aware', 'of', 'it', 'blocking', 'me', 'has', 'shown', 'your', 'support', 'towards', 'your', 'community', 'thanku', 'for', 'that'], tags=[3]), TaggedDocument(words=['the', 'reader', 'here', 'is', 'not', 'going', 'by', 'my', 'say', 'so', 'for', 'ethereal', 'vocal', 'style', 'and', 'dark', 'lyrical', 'content', 'the', 'cited', 'sources', 'in', 'the', 'external', 'links', 'are', 'saying', 'those', 'things', 'if', 'you', 'feel', 'the', 'sources', 'are', 'unreliable', 'or', 'did', 'not', 'represent', 'what', 'they', 'said', 'correctly', 'rewrite', 'or', 'delete', 'it'], tags=[4]), TaggedDocument(words=['fried', 'chickens', 'is', 'dat', 'sum', 'fried', 'chickens'], tags=[5]), TaggedDocument(words=['why', 'can', 'you', 'put', 'english', 'for', 'example', 'on', 'some', 'players', 'but', 'others', 'people', 'don', 'like', 'it', 'why'], tags=[6]), TaggedDocument(words=['guy', 'fawkes', 'im', 'resident', 'in', 'bridgwater', 'and', 'go', 'to', 'the', 'carnival', 'every', 'year', 'im', 'wuite', 'dedicated', 'to', 'the', 'town', 'and', 'enjoy', 'alot', 'about', 'it', 'however', 'think', 'you', 'are', 'wrong', 'although', 'we', 'are', 'rebels', 'think', 'that', 'the', 'carnvial', 'is', 'to', 'celebrate', 'guy', 'fawkes', 'getting', 'caught', 'and', 'therfor', 'preventing', 'it', 'why', 'would', 'you', 'want', 'to', 'celebrate', 'somebody', 'theying', 'to', 'murder', 'out', 'majisty'], tags=[7]), TaggedDocument(words=['as', 'far', 'as', 'nicknames', 'go', 'this', 'article', 'is', 'embarrassing', 'where', 'is', 'the', 'human', 'fish', 'golden', 'fish', 'flying', 'fish', 'and', 'the', 'american', 'super', 'fish', 'among', 'others', 'wiki', 'should', 'be', 'ashamed', 'for', 'this', 'mess', 'of', 'an', 'article', 'anonymous', 'and', 'there', 'signed', 'the', 'post'], tags=[8]), TaggedDocument(words=['woodland', 'meadows', 'good', 'to', 'hear', 'that', 'you', 'corrected', 'that'], tags=[9])]\n"
     ]
    }
   ],
   "source": [
    "print(train_corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 3min 55s, sys: 4min 16s, total: 1h 8min 12s\n",
      "Wall time: 48min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "263558315"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(size=50, min_count=2, iter=55)\n",
    "model.build_vocab(train_corpus)\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./toxic1.d2v')\n",
    "#model = Doc2Vec.load('./toxic1.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hell', 0.6538189053535461),\n",
       " ('piss', 0.6419483423233032),\n",
       " ('shit', 0.6314988732337952),\n",
       " ('fucking', 0.6249221563339233),\n",
       " ('fuk', 0.6218197345733643),\n",
       " ('cunt', 0.5939318537712097),\n",
       " ('moron', 0.5819753408432007),\n",
       " ('assholes', 0.5659811496734619),\n",
       " ('nosy', 0.5601155757904053),\n",
       " ('nigger', 0.5528380870819092)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('fuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
